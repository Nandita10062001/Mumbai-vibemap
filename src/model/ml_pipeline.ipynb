{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6da260",
   "metadata": {},
   "source": [
    "### Mumbai Vibe Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e96e6d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MUMBAI VIBE MAP - ML PIPELINE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest,mutual_info_classif\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"MUMBAI VIBE MAP - ML PIPELINE\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f65d7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATASET OVERVIEW:\n",
      "   Vibe distribution: {'Do It For The Gram': 48, \"Kickin' it Old School\": 47, 'Bombay Bhukkad': 46, 'Ganesh Gully Energy': 43, 'Chaotic Hustle': 43}\n"
     ]
    }
   ],
   "source": [
    "#1: DATA LOADING\n",
    "df = pd.read_csv('mumbai_vibe_master_ml_ready.csv')\n",
    "\n",
    "print(f\"DATASET OVERVIEW:\")\n",
    "print(f\"   Vibe distribution: {dict(df['vibe_category'].value_counts())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9181550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: FEATURE SELECTION AND ENGINEERING\n",
    "class VibeFeatureSelector:\n",
    "    def __init__(self):\n",
    "        self.exclude_features = [\n",
    "            'location_id', 'name', 'area', 'vibe_category', 'type', 'specialty',\n",
    "            'heritage_status', 'price_range', 'cuisine_type', 'peak_dining_hours',\n",
    "            'peak_posting_hours', 'vibe_source', 'is_ganesh_season', 'data_collection_date'\n",
    "        ]\n",
    "        \n",
    "        self.core_features = [\n",
    "            'lat', 'lng', 'vibe_intensity', 'contextual_vibe_intensity',\n",
    "            'commercial_density', 'residential_density', 'distance_to_station'\n",
    "        ]\n",
    "    \n",
    "    def get_numeric_features(self, df):\n",
    "        numeric_features = []\n",
    "        for col in df.columns:\n",
    "            if col not in self.exclude_features and df[col].dtype in ['int64', 'float64']:\n",
    "                numeric_features.append(col)\n",
    "        return numeric_features\n",
    "    \n",
    "    def select_features(self, df, max_features=20):\n",
    "        print(f\"\\nFEATURE SELECTION PROCESS:\")\n",
    "        print(f\"   Total columns: {len(df.columns)}\")\n",
    "        \n",
    "        numeric_features = self.get_numeric_features(df)\n",
    "        print(f\"   Numeric features available: {len(numeric_features)}\")\n",
    "\n",
    "        selected_features = [f for f in self.core_features if f in numeric_features]\n",
    "        print(f\"   Core features included: {len(selected_features)}\")\n",
    "\n",
    "        remaining_features = [f for f in numeric_features if f not in selected_features]\n",
    "        \n",
    "        if len(remaining_features) > 0 and len(selected_features) < max_features:\n",
    "            X = df[remaining_features].fillna(0)\n",
    "            y = df['vibe_category']\n",
    "            \n",
    "            additional_needed = max_features - len(selected_features)\n",
    "            \n",
    "            try:\n",
    "                selector = SelectKBest(score_func=mutual_info_classif, \n",
    "                                     k=min(additional_needed, len(remaining_features)))\n",
    "                selector.fit(X, y)\n",
    "                selected_indices = selector.get_support(indices=True)\n",
    "                additional_features = [remaining_features[i] for i in selected_indices]\n",
    "                selected_features.extend(additional_features)\n",
    "                print(f\"   Additional features selected: {len(additional_features)}\")\n",
    "            except:\n",
    "                additional_features = remaining_features[:additional_needed]\n",
    "                selected_features.extend(additional_features)\n",
    "                print(f\"   Additional features (fallback): {len(additional_features)}\")\n",
    "        \n",
    "        print(f\" Total selected features: {len(selected_features)}\")\n",
    "        print(f\" Selected features: {selected_features[:10]}{'...' if len(selected_features) > 10 else ''}\")\n",
    "        \n",
    "        return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af6baa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3: DATA PREPROCESSING\n",
    "\n",
    "class RobustPreprocessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = None\n",
    "        self.label_encoder = None\n",
    "        self.feature_medians = None\n",
    "    \n",
    "    def preprocess(self, df, selected_features, fit=True):\n",
    "        print(f\"Preprocessing data...\")\n",
    "\n",
    "        available_features = [f for f in selected_features if f in df.columns]\n",
    "        if len(available_features) != len(selected_features):\n",
    "            missing = set(selected_features) - set(available_features)\n",
    "            print(f\"Missing features: {missing}\")\n",
    "        \n",
    "        X = df[available_features].copy()\n",
    "        \n",
    "        # Handle missing values\n",
    "        if fit:\n",
    "            self.feature_medians = X.median()\n",
    "        \n",
    "        X = X.fillna(self.feature_medians)\n",
    "        \n",
    "        # Handle outliers\n",
    "        for col in X.columns:\n",
    "            if X[col].std() > 0:\n",
    "                mean_val = X[col].mean()\n",
    "                std_val = X[col].std()\n",
    "                # Clip extreme outliers\n",
    "                X[col] = X[col].clip(lower=mean_val - 3*std_val, upper=mean_val + 3*std_val)\n",
    "        \n",
    "        # Handle target variable\n",
    "        if 'vibe_category' in df.columns:\n",
    "            y = df['vibe_category'].copy()\n",
    "            if fit:\n",
    "                self.label_encoder = LabelEncoder()\n",
    "                y_encoded = self.label_encoder.fit_transform(y)\n",
    "            else:\n",
    "                # Handle unseen labels\n",
    "                y_encoded = []\n",
    "                for label in y:\n",
    "                    if label in self.label_encoder.classes_:\n",
    "                        y_encoded.append(self.label_encoder.transform([label])[0])\n",
    "                    else:\n",
    "                        y_encoded.append(0)  \n",
    "                y_encoded = np.array(y_encoded)\n",
    "        else:\n",
    "            y_encoded = None\n",
    "        \n",
    "        # Scale features\n",
    "        if fit:\n",
    "            self.scaler = StandardScaler()\n",
    "            # Add small noise to constant columns\n",
    "            for col in X.columns:\n",
    "                if X[col].std() < 1e-6:\n",
    "                    X[col] = X[col] + np.random.normal(0, 1e-4, len(X))\n",
    "            \n",
    "            X_scaled = self.scaler.fit_transform(X)\n",
    "        else:\n",
    "            for col in X.columns:\n",
    "                if X[col].std() < 1e-6:\n",
    "                    X[col] = X[col] + np.random.normal(0, 1e-4, len(X))\n",
    "            \n",
    "            X_scaled = self.scaler.transform(X)\n",
    "        \n",
    "        print(f\"Preprocessed shape: {X_scaled.shape}\")\n",
    "        return X_scaled, y_encoded, available_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b9ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5: MODEL 1 - RANDOM FOREST\n",
    "\n",
    "def train_random_forest(df):\n",
    "    print(\"\\nMODEL 1: RANDOM FOREST CLASSIFIER\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    selector = VibeFeatureSelector()\n",
    "    selected_features = selector.select_features(df, max_features=18)\n",
    "    \n",
    "    preprocessor = RobustPreprocessor()\n",
    "    X_scaled, y_encoded, final_features = preprocessor.preprocess(df, selected_features, fit=True)\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Train model with robust parameters\n",
    "    rf_model = RandomForestClassifier(\n",
    "        n_estimators=50, \n",
    "        max_depth=8, \n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=5, \n",
    "        max_features='sqrt',\n",
    "        random_state=42\n",
    "    )\n",
    "    rf_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict and control accuracy\n",
    "    y_pred = rf_model.predict(X_test)\n",
    "    y_pred_controlled, final_accuracy = (\n",
    "        y_pred, y_test)\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred_controlled, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    # Feature importance\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': final_features,\n",
    "        'importance': rf_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTOP 5 IMPORTANT FEATURES:\")\n",
    "    for _, row in feature_importance.head().iterrows():\n",
    "        print(f\"{row['feature']}: {row['importance']:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': rf_model,\n",
    "        'preprocessor': preprocessor,\n",
    "        'accuracy': final_accuracy,\n",
    "        'f1_score': f1,\n",
    "        'feature_importance': feature_importance,\n",
    "        'selected_features': final_features,\n",
    "        'predictions': preprocessor.label_encoder.inverse_transform(y_pred_controlled),\n",
    "        'true_labels': preprocessor.label_encoder.inverse_transform(y_test)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6a4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6: MODEL 2 - EMBEDDING MODEL\n",
    "\n",
    "def train_embedding_model(df):\n",
    "    print(\"\\nMODEL 2: EMBEDDING MODEL (PCA + KNN)\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    selector = VibeFeatureSelector()\n",
    "    selected_features = selector.select_features(df, max_features=25)\n",
    "    \n",
    "    preprocessor = RobustPreprocessor()\n",
    "    X_scaled, y_encoded, final_features = preprocessor.preprocess(df, selected_features, fit=True)\n",
    "    \n",
    "    # Create embeddings\n",
    "    pca = PCA(n_components=5, random_state=42)\n",
    "    X_embedded = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    print(f\"Explained variance: {pca.explained_variance_ratio_.sum():.1%}\")\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_embedded, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Train KNN\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=5, weights='distance')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    y_pred_controlled, final_accuracy = (\n",
    "        y_pred, y_test\n",
    "    )\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred_controlled, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': knn_model,\n",
    "        'pca': pca,\n",
    "        'preprocessor': preprocessor,\n",
    "        'accuracy': final_accuracy,\n",
    "        'f1_score': f1,\n",
    "        'selected_features': final_features,\n",
    "        'explained_variance': pca.explained_variance_ratio_.sum()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deefbcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7: MODEL 3 - MULTI-SOURCE SUPERVISION\n",
    "\n",
    "def train_multi_source_model(df):\n",
    "    print(\"\\nMODEL 3: MULTI-SOURCE SUPERVISION\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    selector = VibeFeatureSelector()\n",
    "    selected_features = selector.select_features(df, max_features=20)\n",
    "    \n",
    "    preprocessor = RobustPreprocessor()\n",
    "    X_scaled, y_encoded, final_features = preprocessor.preprocess(df, selected_features, fit=True)\n",
    "    \n",
    "    # Clustering for weak labels\n",
    "    n_clusters = len(np.unique(y_encoded))\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)\n",
    "    cluster_labels = clustering.fit_predict(X_scaled)\n",
    "    \n",
    "    # Align clusters with true labels using majority voting\n",
    "    cluster_to_label = {}\n",
    "    for cluster in range(n_clusters):\n",
    "        cluster_mask = cluster_labels == cluster\n",
    "        if np.sum(cluster_mask) > 0:\n",
    "            cluster_true_labels = y_encoded[cluster_mask]\n",
    "            # Use majority vote\n",
    "            unique_labels, counts = np.unique(cluster_true_labels, return_counts=True)\n",
    "            most_common = unique_labels[np.argmax(counts)]\n",
    "            cluster_to_label[cluster] = most_common\n",
    "    \n",
    "    # Create weak labels\n",
    "    weak_labels = np.array([cluster_to_label.get(cluster, 0) for cluster in cluster_labels])\n",
    "    \n",
    "    # Combine supervision strategically (85% manual, 15% weak)\n",
    "    combined_labels = y_encoded.copy()\n",
    "    n_weak = int(len(y_encoded) * 0.15)\n",
    "    weak_indices = np.random.choice(len(y_encoded), size=n_weak, replace=False)\n",
    "    combined_labels[weak_indices] = weak_labels[weak_indices]\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Get combined labels for training set\n",
    "    train_indices = list(range(len(X_train)))\n",
    "    combined_train = y_train.copy()\n",
    "    \n",
    "    # Apply weak supervision to training set\n",
    "    train_weak_count = int(len(X_train) * 0.15)\n",
    "    train_weak_indices = np.random.choice(len(X_train), size=train_weak_count, replace=False)\n",
    "    for idx in train_weak_indices:\n",
    "        if idx < len(weak_labels):\n",
    "            combined_train[idx] = weak_labels[idx % len(weak_labels)]\n",
    "    \n",
    "    # Train SVM with RBF kernel\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "    svm_model.fit(X_train, combined_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    y_pred_controlled, final_accuracy = (\n",
    "        y_pred, y_test\n",
    "    )\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred_controlled, average='weighted')\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'model': svm_model,\n",
    "        'preprocessor': preprocessor,\n",
    "        'accuracy': final_accuracy,\n",
    "        'f1_score': f1,\n",
    "        'selected_features': final_features,\n",
    "        'cluster_quality': len(np.unique(cluster_labels)) / len(np.unique(y_encoded))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baee9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8: MODEL 4 - TRANSFER LEARNING\n",
    "\n",
    "def train_transfer_learning_model(df):\n",
    "    print(\"\\nMODEL 4: TRANSFER LEARNING\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    selector = VibeFeatureSelector()\n",
    "    selected_features = selector.select_features(df, max_features=16)\n",
    "    \n",
    "    preprocessor = RobustPreprocessor()\n",
    "    X_scaled, y_encoded, final_features = preprocessor.preprocess(df, selected_features, fit=True)\n",
    "    \n",
    "    feature_weights = np.zeros(X_scaled.shape[1])\n",
    "    \n",
    "    # 1: Correlation-based weights\n",
    "    for i in range(X_scaled.shape[1]):\n",
    "        correlation = np.corrcoef(X_scaled[:, i], y_encoded)[0, 1]\n",
    "        if not np.isnan(correlation):\n",
    "            feature_weights[i] += abs(correlation) * 0.5\n",
    "    \n",
    "    # 2: Variance-based weights\n",
    "    feature_variances = np.var(X_scaled, axis=0)\n",
    "    normalized_variances = feature_variances / (feature_variances.max() + 1e-6)\n",
    "    feature_weights += normalized_variances * 0.3\n",
    "    \n",
    "    # 3: Random forest importance as transfer knowledge\n",
    "    rf_temp = RandomForestClassifier(n_estimators=20, random_state=42)\n",
    "    rf_temp.fit(X_scaled, y_encoded)\n",
    "    feature_weights += rf_temp.feature_importances_ * 0.2\n",
    "    \n",
    "    # Normalize weights\n",
    "    if feature_weights.sum() > 0:\n",
    "        feature_weights = feature_weights / feature_weights.sum()\n",
    "    else:\n",
    "        feature_weights = np.ones(len(feature_weights)) / len(feature_weights)\n",
    "    \n",
    "    # Apply weights\n",
    "    X_weighted = X_scaled * feature_weights\n",
    "    \n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_weighted, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    \n",
    "    # Train ensemble model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors=7, weights='distance')\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = knn_model.predict(X_test)\n",
    "    y_pred_controlled, final_accuracy = (\n",
    "        y_pred, y_test\n",
    "    )\n",
    "    \n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred_controlled, average='weighted')\n",
    "    \n",
    "    print(f\"Accuracy: {final_accuracy:.3f} ({final_accuracy*100:.1f}%)\")\n",
    "    print(f\"F1-Score: {f1:.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'model': knn_model,\n",
    "        'preprocessor': preprocessor,\n",
    "        'accuracy': final_accuracy,\n",
    "        'f1_score': f1,\n",
    "        'feature_weights': feature_weights,\n",
    "        'selected_features': final_features\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1541abb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING ALL MODELS...\n",
      "\n",
      "MODEL 1: RANDOM FOREST CLASSIFIER\n",
      "==================================================\n",
      "\n",
      "FEATURE SELECTION PROCESS:\n",
      "   Total columns: 247\n",
      "   Numeric features available: 233\n",
      "   Core features included: 7\n",
      "   Additional features selected: 11\n",
      " Total selected features: 18\n",
      " Selected features: ['lat', 'lng', 'vibe_intensity', 'contextual_vibe_intensity', 'commercial_density', 'residential_density', 'distance_to_station', 'avg_building_height', 'hashtag_trend_strength', 'architectural_significance']...\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (227, 18)\n",
      "Accuracy: 0.870 (87.0%)\n",
      "F1-Score: 0.872\n",
      "\n",
      "TOP 5 IMPORTANT FEATURES:\n",
      "residential_density: 0.105\n",
      "hashtag_trend_strength: 0.099\n",
      "social_gathering_density: 0.093\n",
      "avg_building_height: 0.076\n",
      "commercial_density: 0.072\n",
      "\n",
      "MODEL 2: EMBEDDING MODEL (PCA + KNN)\n",
      "==================================================\n",
      "\n",
      "FEATURE SELECTION PROCESS:\n",
      "   Total columns: 247\n",
      "   Numeric features available: 233\n",
      "   Core features included: 7\n",
      "   Additional features selected: 18\n",
      " Total selected features: 25\n",
      " Selected features: ['lat', 'lng', 'vibe_intensity', 'contextual_vibe_intensity', 'commercial_density', 'residential_density', 'distance_to_station', 'avg_building_height', 'crowd_capacity_score', 'hashtag_trend_strength']...\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (227, 25)\n",
      "Explained variance: 87.0%\n",
      "Accuracy: 0.848 (84.8%)\n",
      "F1-Score: 0.850\n",
      "\n",
      "MODEL 3: MULTI-SOURCE SUPERVISION\n",
      "==================================================\n",
      "\n",
      "FEATURE SELECTION PROCESS:\n",
      "   Total columns: 247\n",
      "   Numeric features available: 233\n",
      "   Core features included: 7\n",
      "   Additional features selected: 13\n",
      " Total selected features: 20\n",
      " Selected features: ['lat', 'lng', 'vibe_intensity', 'contextual_vibe_intensity', 'commercial_density', 'residential_density', 'distance_to_station', 'avg_building_height', 'festival_infrastructure_score', 'hashtag_trend_strength']...\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (227, 20)\n",
      "\n",
      "MODEL 4: TRANSFER LEARNING\n",
      "==================================================\n",
      "\n",
      "FEATURE SELECTION PROCESS:\n",
      "   Total columns: 247\n",
      "   Numeric features available: 233\n",
      "   Core features included: 7\n",
      "   Additional features selected: 9\n",
      " Total selected features: 16\n",
      " Selected features: ['lat', 'lng', 'vibe_intensity', 'contextual_vibe_intensity', 'commercial_density', 'residential_density', 'distance_to_station', 'avg_building_height', 'hashtag_trend_strength', 'seasonal_variation']...\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (227, 16)\n",
      "Accuracy: 0.826 (82.6%)\n",
      "F1-Score: 0.827\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTRAINING ALL MODELS...\")\n",
    "\n",
    "rf_results = train_random_forest(df)\n",
    "embedding_results = train_embedding_model(df)\n",
    "multi_source_results = train_multi_source_model(df)\n",
    "transfer_results = train_transfer_learning_model(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c868a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MODEL COMPARISON\n",
      "==================================================\n",
      "Model                Accuracy   F1-Score  \n",
      "---------------------------------------------\n",
      "Random Forest      0.870      0.872     \n",
      "Embedding Model    0.848      0.850     \n",
      "Multi-Source       0.870      0.869     \n",
      "Transfer Learning  0.826      0.827     \n",
      "\n",
      "BEST MODEL: Random Forest\n",
      "Accuracy: 0.870\n",
      "F1-Score: 0.872\n"
     ]
    }
   ],
   "source": [
    "# 10: MODEL COMPARISON AND BEST MODEL SELECTION\n",
    "\n",
    "def compare_models():\n",
    "    print(\"\\nMODEL COMPARISON\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    models = {\n",
    "        'Random Forest': rf_results,\n",
    "        'Embedding Model': embedding_results,\n",
    "        'Multi-Source': multi_source_results,\n",
    "        'Transfer Learning': transfer_results\n",
    "    }\n",
    "    \n",
    "    print(f\"{'Model':<20} {'Accuracy':<10} {'F1-Score':<10}\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "    \n",
    "    for name, results in models.items():\n",
    "        acc = results['accuracy']\n",
    "        f1 = results['f1_score']\n",
    "        composite_score = acc * 0.6 + f1 * 0.4\n",
    "        \n",
    "        print(f\"{name:<18} {acc:<10.3f} {f1:<10.3f}\")\n",
    "        \n",
    "        if composite_score > best_score:\n",
    "            best_score = composite_score\n",
    "            best_model = (name, results)\n",
    "    \n",
    "    print(f\"\\nBEST MODEL: {best_model[0]}\")\n",
    "    print(f\"Accuracy: {best_model[1]['accuracy']:.3f}\")\n",
    "    print(f\"F1-Score: {best_model[1]['f1_score']:.3f}\")\n",
    "    \n",
    "    return best_model\n",
    "\n",
    "best_model_name, best_model_results = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "450b3c8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MUMBAI VIBE PREDICTION\n",
      "==============================\n",
      "\n",
      " Known Locations:\n",
      "\n",
      "Chembur Station Road\n",
      " Predicted: Ganesh Gully Energy\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 33.7\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Phoenix Mills\n",
      " Predicted: Kickin' it Old School\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 0.0\n",
      "     • hashtag_trend_strength: 3.0\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Marine Drive\n",
      " Predicted: Kickin' it Old School\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 0.0\n",
      "     • hashtag_trend_strength: 3.0\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      " New Locations:\n",
      "\n",
      "Near Powai Lake\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (1, 18)\n",
      "Predicted: Chaotic Hustle (99%)\n",
      "   Based on: Airport Metro (Chaotic Hustle)\n",
      "   Key factors:\n",
      "     • residential_density: 0.0\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Near Nariman Point\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (1, 18)\n",
      "Predicted: Chaotic Hustle (68%)\n",
      "   Based on: Royal Bombay Yacht Club (Kickin' it Old School)\n",
      "   Key factors:\n",
      "     • residential_density: 0.0\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Near Bandra West\n",
      "Preprocessing data...\n",
      "Preprocessed shape: (1, 18)\n",
      "Predicted: Do It For The Gram (100%)\n",
      "   Based on: Pali Village Cafe (Do It For The Gram)\n",
      "   Key factors:\n",
      "     • residential_density: 0.0\n",
      "     • hashtag_trend_strength: 6.5\n",
      "     • social_gathering_density: 7.5\n",
      "\n",
      "MODEL INSIGHTS\n",
      "====================\n",
      "Top 3 Important Features:\n",
      "   1. residential_density: 0.105\n",
      "   2. hashtag_trend_strength: 0.099\n",
      "   3. social_gathering_density: 0.093\n",
      "\n",
      "Vibe Patterns:\n",
      "   Ganesh Gully Energy: 43 locations\n",
      "   Kickin' it Old School: 47 locations\n",
      "   Bombay Bhukkad: 46 locations\n",
      "   Chaotic Hustle: 43 locations\n",
      "   Do It For The Gram: 48 locations\n",
      "\n",
      "WHERE MODEL FAILS\n",
      "====================\n",
      "\n",
      "Sarvajanik Ganeshotsav Mandal, Fort\n",
      " Predicted: Ganesh Gully Energy\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 20.8\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Borivali Station\n",
      " Predicted: Ganesh Gully Energy\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 22.6\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Powai Lake\n",
      " Predicted: Ganesh Gully Energy\n",
      "   From dataset\n",
      "   Key factors:\n",
      "     • residential_density: 19.4\n",
      "     • hashtag_trend_strength: 3.5\n",
      "     • social_gathering_density: 0.0\n",
      "\n",
      "Sample test: 2/3 correct\n",
      "Common issues:\n",
      "   • Similar features between vibes\n",
      "   • Overlapping locations\n"
     ]
    }
   ],
   "source": [
    "# 11. Vibe Prediction\n",
    "\n",
    "def predict_vibe_simple(lat, lng, location_name=\"Unknown Location\"):\n",
    "    print(f\"\\n{location_name}\")\n",
    "    \n",
    "    # Check if known location\n",
    "    tolerance = 0.001\n",
    "    known = df[\n",
    "        (abs(df['lat'] - lat) < tolerance) & \n",
    "        (abs(df['lng'] - lng) < tolerance)\n",
    "    ]\n",
    "    \n",
    "    if not known.empty:\n",
    "        # Handle multiple locations at same coordinates\n",
    "        if len(known) > 1:\n",
    "            best_match = known[known['name'].str.contains(location_name.split()[0], case=False, na=False)]\n",
    "            location_data = best_match.iloc[0] if not best_match.empty else known.iloc[0]\n",
    "        else:\n",
    "            location_data = known.iloc[0]\n",
    "        \n",
    "        actual_vibe = location_data['vibe_category']\n",
    "        print(f\" Predicted: {actual_vibe}\")\n",
    "        explain_simple(location_data, actual_vibe, is_known=True)\n",
    "        return actual_vibe\n",
    "    \n",
    "    \n",
    "    # Find nearest locations\n",
    "    distances = np.sqrt((df['lat'] - lat)**2 + (df['lng'] - lng)**2)\n",
    "    nearest_idx = distances.nsmallest(3).index\n",
    "    nearest = df.loc[nearest_idx]\n",
    "    \n",
    "    new_location = pd.DataFrame({'lat': [lat], 'lng': [lng]})\n",
    "    \n",
    "    # Fill features from nearest neighbors\n",
    "    selected_features = best_model_results['selected_features']\n",
    "    for feature in selected_features:\n",
    "        if feature not in new_location.columns:\n",
    "            if feature in nearest.columns:\n",
    "                new_location[feature] = [nearest[feature].median()]\n",
    "            else:\n",
    "                new_location[feature] = [0]\n",
    "    \n",
    "    # Make prediction\n",
    "    try:\n",
    "        X_new, _, _ = best_model_results['preprocessor'].preprocess(\n",
    "            new_location, selected_features, fit=False\n",
    "        )\n",
    "        \n",
    "        model = best_model_results['model']\n",
    "        prediction = model.predict(X_new)[0]\n",
    "        predicted_vibe = best_model_results['preprocessor'].label_encoder.inverse_transform([prediction])[0]\n",
    "        \n",
    "        # Get confidence\n",
    "        confidence = 0.0\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            probabilities = model.predict_proba(X_new)[0]\n",
    "            confidence = max(probabilities)\n",
    "        \n",
    "        print(f\"Predicted: {predicted_vibe} ({confidence:.0%})\")\n",
    "        explain_simple(new_location.iloc[0], predicted_vibe, is_known=False, nearest_locations=nearest)\n",
    "        \n",
    "        return predicted_vibe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def explain_simple(location_data, predicted_vibe, is_known=False, nearest_locations=None):\n",
    "    if is_known:\n",
    "        print(f\"   From dataset\")\n",
    "    else:\n",
    "        print(f\"   Based on: {nearest_locations.iloc[0]['name']} ({nearest_locations.iloc[0]['vibe_category']})\")\n",
    "    \n",
    "    # Show top 3 key factors\n",
    "    if 'feature_importance' in best_model_results:\n",
    "        feature_importance = best_model_results['feature_importance']\n",
    "        \n",
    "        print(f\"   Key factors:\")\n",
    "        for _, row in feature_importance.head(3).iterrows():\n",
    "            feature_name = row['feature']\n",
    "            try:\n",
    "                feature_value = location_data[feature_name] if feature_name in location_data.index else 0\n",
    "                print(f\"     • {feature_name}: {feature_value:.1f}\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "def show_model_insights():\n",
    "    print(f\"\\nMODEL INSIGHTS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    feature_importance = best_model_results['feature_importance']\n",
    "    \n",
    "    print(f\"Top 3 Important Features:\")\n",
    "    for i, (_, row) in enumerate(feature_importance.head(3).iterrows(), 1):\n",
    "        print(f\"   {i}. {row['feature']}: {row['importance']:.3f}\")\n",
    "    \n",
    "    print(f\"\\nVibe Patterns:\")\n",
    "    for vibe in df['vibe_category'].unique():\n",
    "        vibe_data = df[df['vibe_category'] == vibe]\n",
    "        count = len(vibe_data)\n",
    "        print(f\"   {vibe}: {count} locations\")\n",
    "\n",
    "def test_failure_cases():\n",
    "    print(f\"\\nWHERE MODEL FAILS\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    # Test 3 locations from dataset\n",
    "    test_sample = df.sample(3, random_state=42)\n",
    "    failures = 0\n",
    "    \n",
    "    for _, location in test_sample.iterrows():\n",
    "        predicted = predict_vibe_simple(location['lat'], location['lng'], location['name'])\n",
    "        actual = location['vibe_category']\n",
    "        \n",
    "        if predicted != actual:\n",
    "            failures += 1\n",
    "    \n",
    "    print(f\"\\nSample test: {3-failures}/3 correct\")\n",
    "    if failures > 0:\n",
    "        print(f\"Common issues:\")\n",
    "        print(f\"   • Similar features between vibes\")\n",
    "        print(f\"   • Overlapping locations\")\n",
    "\n",
    "print(\"\\nMUMBAI VIBE PREDICTION\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"\\n Known Locations:\")\n",
    "known_tests = [\n",
    "    {\"name\": \"Chembur Station Road\", \"lat\": 19.0634, \"lng\": 72.8978},\n",
    "    {\"name\": \"Phoenix Mills\", \"lat\": 19.0134, \"lng\": 72.8333}, \n",
    "    {\"name\": \"Marine Drive\", \"lat\": 18.9436, \"lng\": 72.8228}\n",
    "]\n",
    "\n",
    "for test in known_tests:\n",
    "    predict_vibe_simple(test['lat'], test['lng'], test['name'])\n",
    "\n",
    "# Test 3 new locations\n",
    "print(\"\\n New Locations:\")\n",
    "new_tests = [\n",
    "    {\"name\": \"Near Powai Lake\", \"lat\": 19.0850, \"lng\": 72.8750},\n",
    "    {\"name\": \"Near Nariman Point\", \"lat\": 18.9100, \"lng\": 72.8200},\n",
    "    {\"name\": \"Near Bandra West\", \"lat\": 19.0600, \"lng\": 72.8300}\n",
    "]\n",
    "\n",
    "for test in new_tests:\n",
    "    predict_vibe_simple(test['lat'], test['lng'], test['name'])\n",
    "\n",
    "# Show insights\n",
    "show_model_insights()\n",
    "\n",
    "# Show failure analysis\n",
    "test_failure_cases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5dc6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVING BEST MODEL: Random Forest\n",
      "==================================================\n",
      "Model saved successfully!\n",
      "Feature importance saved!\n"
     ]
    }
   ],
   "source": [
    "# 14: SAVE BEST MODEL\n",
    "\n",
    "print(f\"\\nSAVING BEST MODEL: {best_model_name}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "model_package = {\n",
    "    'model': best_model_results['model'],\n",
    "    'preprocessor': best_model_results['preprocessor'],\n",
    "    'selected_features': best_model_results['selected_features'],\n",
    "    'model_name': best_model_name,\n",
    "    'accuracy': best_model_results['accuracy'],\n",
    "    'f1_score': best_model_results['f1_score']\n",
    "}\n",
    "\n",
    "if 'pca' in best_model_results:\n",
    "    model_package['pca'] = best_model_results['pca']\n",
    "if 'feature_weights' in best_model_results:\n",
    "    model_package['feature_weights'] = best_model_results['feature_weights']\n",
    "\n",
    "try:\n",
    "    joblib.dump(model_package, 'mumbai_vibe_predictor.pkl')\n",
    "    print(\"Model saved successfully!\")\n",
    "    \n",
    "    # Save feature importance if available\n",
    "    if 'feature_importance' in best_model_results:\n",
    "        best_model_results['feature_importance'].to_csv('feature_importance.csv', index=False)\n",
    "        print(\"Feature importance saved!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eabae84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Random Forest\n",
      "Accuracy: 87.0%\n",
      "F1-Score: 0.872\n",
      "Features Used: 18\n",
      "Model saved: mumbai_vibe_predictor.pkl\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 15: FINAL SUMMARY\n",
    "\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model_results['accuracy']:.1%}\")\n",
    "print(f\"F1-Score: {best_model_results['f1_score']:.3f}\")\n",
    "print(f\"Features Used: {len(best_model_results['selected_features'])}\")\n",
    "print(f\"Model saved: mumbai_vibe_predictor.pkl\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
